Données

Dans presque tous les cas, les attaquants sont intéressés par les données :

Stockées dans une base de données
Stockées sur disque dans des machines virtuelles
Stockées dans une application SaaS comme Office 365
Stockées dans un stockage cloud
C’est à ceux qui stockent les données et en contrôlent l’accès qu’il revient de s’assurer qu’elles sont bien sécurisées. Ce sont souvent des réglementations qui dictent la mise en place de contrôles et de processus pour garantir la confidentialité, l’intégrité et la disponibilité des données.

Image d’un fichier sur le réseau

Application

Garantir que les applications sont sécurisées et sans vulnérabilités.
Stocker les secrets des applications sensibles dans un support de stockage sécurisé.
Intégrer la sécurité dans la conception tout au long du développement d’application.
L’intégration de la sécurité dans le cycle de vie du développement d’application permet de réduire le nombre de vulnérabilités introduites dans le code. Nous encourageons toutes les équipes de développement à vérifier que leurs applications sont sécurisées par défaut et à ne faire aucun compromis sur les exigences de sécurité.

Terminal représentant un calcul

Calcul

Sécuriser l’accès aux machines virtuelles.
Implémenter une protection des points de terminaison et faire en sorte que les systèmes soient constamment corrigés et actualisés.
Les logiciels malveillants, les systèmes non corrigés et les systèmes mal sécurisés exposent votre environnement aux attaques. Cette couche a pour fonction principale de garantir la sécurité de vos ressources de calcul et de vous permettre de mettre en place les contrôles appropriés pour limiter au maximum les problèmes de sécurité.

Trois systèmes connectés représentant la mise en réseau

Réseau

Limiter la communication entre ressources.
Refuser par défaut.
Limiter l’accès Internet entrant et limiter l’accès sortant en fonction des besoins.
Implémenter une connectivité sécurisée dans les réseaux locaux.
Au niveau de cette couche, le but principal est de limiter la connectivité réseau de toutes vos ressources pour autoriser uniquement ce qui est nécessaire. En limitant cette communication, vous réduisez le risque de mouvements latéraux dans votre réseau.

Barrière physique représentant le périmètre du réseau

Périmètre

Utiliser une protection contre le déni de service distribué (DDoS) pour filtrer les attaques à grande échelle avant qu’elles ne provoquent un déni de service pour les utilisateurs finaux.
Utiliser des pare-feu de périmètre pour identifier les attaques malveillantes contre votre réseau et vous en alerter.
Dans le périmètre du réseau, il s’agit de protéger vos ressources contre les attaques basées sur le réseau. Pour que votre réseau reste sécurisé, vous devez identifier ces attaques, réduire leur impact à néant et créer des alertes quand elles se produisent.

Badge représentant un accès sécurisé

Identité et accès

Contrôler l’accès à l’infrastructure et contrôler les modifications.
Utiliser l’authentification unique et l’authentification multifacteur.
Auditer les événements et les modifications.
La couche d’identité et d’accès veille à ce que les identités soient sécurisées, que l’accès accordé corresponde au strict nécessaire et que les modifications soient consignées.

Caméra de sécurité représentant la sécurité physique

Sécurité physique

Dans le centre de données, la première ligne de défense est la sécurité du bâtiment, ainsi que le contrôle de l’accès au matériel informatique.
La sécurité physique apporte une protection physique contre l’accès aux ressources. Elle garantit que les autres couches ne peuvent pas être contournées et que la perte ou le vol sont gérés correctement.



Azure Security Center est un très bon point de départ pour examiner la sécurité de votre solution Azure. Security Center est un service de supervision qui assure une protection contre les menaces sur l’ensemble de vos services, à la fois dans Azure et en local. Security Center peut :

Fournir des suggestions de sécurité basées sur vos configurations, ressources et réseaux.
Surveiller les paramètres de sécurité sur les charges de travail locales et cloud, et appliquer automatiquement la sécurité requise aux nouveaux services mis en ligne.
Superviser en permanence tous vos services, et effectuer des évaluations de la sécurité automatiques pour identifier les vulnérabilités potentielles avant leur exploitation éventuelle.
Utiliser le machine learning pour détecter et bloquer l’installation de logiciels malveillants sur vos machines virtuelles et les services. Vous pouvez également créer une liste des applications autorisées pour vous assurer que seules les applications approuvées pourront être exécutées.
Analyser et identifier les attaques entrantes potentielles, et examiner les menaces et toute activité après violation de la sécurité pouvant s’être produite.
Contrôler l’accès juste-à-temps aux ports, et réduire ainsi la surface d’attaque en veillant à ce que le réseau n’autorise que le trafic strictement nécessaire.
Azure Security Center fait partie des recommandations du CIS (Center for Internet Security).

Image illustrant Azure Security Center

Niveaux disponibles
Azure Security Center est disponible en deux niveaux :

Gratuit. Inclus avec votre abonnement Azure, ce niveau se limite aux évaluations et recommandations de ressources Azure uniquement.
Standard. Ce niveau fournit une suite complète de services de sécurité, notamment la supervision continue, la détection des menaces, le contrôle de l’accès juste-à-temps pour les ports, et bien d’autres services.
Pour accéder à la suite complète des services Azure Security Center, vous devez passer à un abonnement de niveau Standard. Vous pouvez profiter de l’essai gratuit de 30 jours à partir du tableau de bord Azure Security Center dans le portail Azure. À la fin de la période d’essai de 30 jours, Azure Security Center est facturé 15 $ par nœud et par mois.

Scénarios d’usage
Vous pouvez intégrer Security Center dans vos workflows et l’utiliser de nombreuses façons. Voici deux exemples.

Utilisez Security Center pour la réponse aux incidents.

Trop souvent, les organisations apprennent à répondre aux incidents seulement après avoir subi une attaque. Pour réduire les coûts et les dommages, il est important de mettre en place un plan de réponse aux incidents avant qu’une attaque ne survienne. Vous pouvez utiliser Azure Security Center à différentes étapes de la réponse à un incident.

Flèches circulaires illustrant les différentes phases (détecter, évaluer, diagnostiquer, stabiliser, fermer)

Vous pouvez utiliser Security Center pendant les phases de détection, d’évaluation et de diagnostic. Voici des exemples de l’utilité de Security Center durant les trois étapes initiales de réponse aux incidents :

Détecter. Examiner le premier signe de l’examen d’un événement. Par exemple, vous pouvez utiliser le tableau de bord de Security Center pour examiner la vérification initiale du déclenchement d’une alerte de sécurité de haute priorité.
Évaluer. Procéder à l’évaluation initiale pour obtenir plus d’informations sur l’activité suspecte. Par exemple, vous pouvez afficher des informations supplémentaires sur l’alerte de sécurité.
Diagnostiquer. Mener une investigation technique et identifier les stratégies de confinement, d’atténuation et de contournement. Par exemple, suivez les étapes de correction décrites par Security Center dans cette alerte de sécurité spécifique.
Utilisez les recommandations Security Center pour renforcer la sécurité.

Vous pouvez réduire les risques d’un incident de sécurité grave en configurant une stratégie de sécurité, puis en implémentant les recommandations fournies par Azure Security Center.

Une stratégie de sécurité définit l’ensemble des contrôles recommandés pour les ressources d’un abonnement ou groupe de ressources spécifique. Dans Security Center, vous définissez les stratégies conformément aux exigences de sécurité de votre entreprise.
Security Center analyse l’état de sécurité de vos ressources Azure. Lorsque Security Center identifie des failles de sécurité potentielles, il crée des recommandations en fonction des contrôles définis dans la stratégie de sécurité. Ces recommandations vous guident tout au long du processus de configuration des contrôles de sécurité nécessaires. Par exemple, si certaines de vos charges de travail ne nécessitent pas la stratégie Azure SQL Database Transparent Data Encryption (TDE), désactivez cette stratégie au niveau de l’abonnement et activez-la uniquement dans les groupes de ressources qui la requièrent.
 Important

Pour passer un abonnement au niveau Standard, vous devez avoir le rôle Propriétaire de l’abonnement, Contributeur de l’abonnement ou Administrateur de la sécurité.


Identité et accès
10 minutes
Les périmètres réseau, les pare-feu et les contrôles d’accès physique étaient auparavant la protection principale des données d’entreprise. Mais les périmètres réseau sont devenus de plus en plus poreux avec l’explosion des appareils BYOD (Apportez votre propre appareil), des applications mobiles et des applications cloud.

L’identité est devenue la nouvelle limite de sécurité principale. Ainsi, une authentification correcte et l’attribution de privilèges sont essentielles pour conserver le contrôle de vos données.

Les services de livraison de Contoso Shipping, votre entreprise, se concentrent sur ces problèmes. La nouvelle solution de cloud hybride de votre équipe doit prendre en compte le fait que des applications mobiles ont accès aux secrets quand un utilisateur autorisé est connecté à —, outre le fait que les véhicules de livraison envoient un flux constant de données de télémétrie qui sont essentielles pour optimiser l’activité de l’entreprise.

Authentification et autorisation
L’authentification et l’autorisation sont deux concepts fondamentaux qu’il est impératif de bien comprendre quand on parle de contrôle d’accès et d’identité. De ces concepts découle tout le reste qui se produit de manière séquentielle dans n’importe quel processus de contrôle d’identité et d’accès :

L’authentification est le processus qui consiste à établir l’identité d’un utilisateur ou d’un service cherchant à accéder à une ressource. Ce processus comprend l’action de demander à une partie des informations d’identification légitimes, et fournit la base de la création d’un principal de sécurité à des fins de contrôle d’identité et d’accès. Il détermine si la partie est bien ce qu’elle prétend être.

L’autorisation est le processus visant à établir le niveau d’accès dont dispose un utilisateur ou un service authentifié. Elle détermine les données auxquelles ils ont accès et l’utilisation qu’ils peuvent en faire.

 Notes

L’authentification et l’autorisation sont parfois abrégées en AuthN et AuthZ, respectivement.

Azure fournit des services pour gérer l’authentification et l’autorisation par le biais d’Azure Active Directory (Azure AD).

Qu’est-ce qu’Azure Active Directory ?
Azure AD est un service d’identité dans le cloud. Il prend nativement en charge la synchronisation de votre annuaire local Active Directory existant, ou peut être utilisé de manière autonome. Cela signifie que toutes vos applications, qu’elles soient locales, dans le cloud (comme Office 365) ou mobiles, peuvent partager les mêmes informations d’identification. Les développeurs et les administrateurs peuvent contrôler l’accès aux applications et données internes et externes en utilisant des règles et des stratégies centralisées configurées dans Azure AD.

Azure AD fournit les services suivants :

Authentification. Ce processus inclut la vérification de l’identité avant d’accéder aux applications et aux ressources, ainsi que plusieurs fonctionnalités telles que la réinitialisation de mot de passe en libre-service, l’authentification multifacteur (MFA), une liste de mots de passe interdits personnalisée et des services de verrouillage intelligent.
Authentification unique (SSO). Avec l’authentification unique, les utilisateurs peuvent se servir d’un seul ID et d’un seul mot de passe pour accéder à plusieurs applications. Une identité unique est liée à un utilisateur, ce qui simplifie le modèle de sécurité. Quand un utilisateur change de rôle ou quitte l’organisation, les modifications d’accès s’appliquent à cette identité, ce qui réduit considérablement le travail nécessaire pour changer ou désactiver les comptes.
Gestion des applications. Vous pouvez gérer vos applications cloud et locales avec le proxy d’application Azure AD, l’authentification unique, le portail Mes applications (également appelé panneau d’accès) et les applications SaaS.
Services d’identité B2B (entreprise-entreprise). Gérer vos utilisateurs invités et vos partenaires externes tout en conservant le contrôle de vos données d’entreprise
Services d’identité B2C (entreprise-client). Personnalisez et contrôlez la façon dont les utilisateurs s’inscrivent, se connectent et gèrent leurs profils quand ils utilisent vos applications avec des services.
Gestion des appareils. Gérez la façon dont vos appareils cloud ou locaux accèdent à vos données d’entreprise.
Examinons quelques-uns de ces services plus en détail.

Authentification unique
Plus les identités que l’utilisateur doit gérer sont nombreuses, plus le risque d’un incident de sécurité lié aux informations d’identification est grand. Plus il y a d’identités, plus il y a de mots de passe à mémoriser et à changer. Les stratégies de mot de passe peuvent varier selon les applications et, comme les exigences de complexité augmentent, les utilisateurs ont de plus en plus de mal à mémoriser les mots de passe.

Examinez à présent la logistique derrière la gestion de toutes ces identités. C’est une charge supplémentaire pour le support technique qui doit alors gérer les verrouillages des comptes et les demandes de réinitialisation des mots de passe. Quand un utilisateur quitte une organisation, il faut pouvoir retrouver toutes ces identités et les désactiver, ce qui n’est pas toujours facile. Si une identité est oubliée, elle peut autoriser un accès alors qu’elle aurait dû être éliminée.

Avec l’authentification unique, les utilisateurs doivent mémoriser un seul ID et un seul mot de passe. L’accès aux applications est accordé à une identité unique liée à un utilisateur, ce qui simplifie le modèle de sécurité. Lorsqu’un utilisateur change de rôle ou quitte l’organisation, les modifications d’accès sont liées à l’identité unique. L’effort nécessaire pour changer ou désactiver les comptes est donc considérablement réduit. L’utilisation de l’authentification unique pour les comptes facilite la gestion des identités par les utilisateurs et augmente les fonctionnalités de sécurité dans votre environnement.

Empreinte numérique représentant Azure Active Directory

Authentification unique avec Azure Active Directory

En utilisant Azure AD pour l’authentification unique, vous avez également la possibilité de combiner plusieurs sources de données dans un schéma de sécurité intelligent. Ce schéma de sécurité permet de fournir une analyse des menaces et une protection des identités en temps réel à tous les comptes dans Azure AD, notamment les comptes qui sont synchronisés à partir de votre annuaire AD local. En utilisant un fournisseur d’identité centralisé, vous bénéficiez de la centralisation des contrôles de sécurité, des rapports, des alertes et de l’administration de votre infrastructure d’identités.

Tandis que Contoso Shipping intègre son instance Active Directory existante à Azure AD, vous faites en sorte que le contrôle des accès soit ainsi cohérent à travers l’organisation. Cela vous permet de considérablement simplifier la capacité de vous connecter à la messagerie et aux documents Office 365 sans vous réauthentifier.

Authentification multifacteur
L’authentification multifacteur (MFA) fournit une sécurité supplémentaire pour vos identités en exigeant au moins deux éléments pour une authentification complète. Ces éléments se répartissent en trois catégories :

Quelque chose que vous connaissez
Quelque chose que vous possédez
Quelque chose que vous êtes
Quelque chose que vous connaissez : il peut s’agir d’un mot de passe ou de la réponse à une question de sécurité. Quelque chose que vous possédez : il peut s’agir d’une application mobile qui reçoit une notification ou un appareil de génération de jetons. Quelque chose que vous êtes : en général, il s’agit d’une sorte de propriété biométrique, comme l’analyse faciale ou d’empreinte digitale utilisée sur de nombreux appareils mobiles.

L’utilisation de la MFA augmente la sécurité de votre identité en réduisant l’impact de l’exposition des informations d’identification. Un attaquant qui connaît le mot de passe d’un utilisateur doit aussi disposer de son téléphone ou de son visage pour s’authentifier complètement. Si un seul facteur est vérifié, l’authentification est insuffisante et l’attaquant ne peut pas utiliser uniquement ces informations d’identification pour s’authentifier. Les avantages de sécurité sont considérables, et nous insistons sur l’importance d’activer l’authentification multifacteur dès que la situation le permet.

Azure AD intègre des fonctionnalités MFA et est compatible avec d’autres fournisseurs de MFA tiers. MFA doit être utilisé pour les utilisateurs qui ont le rôle Administrateur général dans Azure AD, car ces comptes sont hautement sensibles. MFA peut aussi être activé pour tous les autres comptes.

Pour Contoso Shipping, vous décidez d’activer MFA chaque fois qu’un utilisateur se connecte depuis un ordinateur non connecté à un domaine, notamment les applications mobiles utilisées par vos chauffeurs.

Distribution d’identités aux services
Les identités sont souvent utiles pour les services. Souvent, contrairement aux bonnes pratiques, les informations d’identification sont incorporées dans des fichiers de configuration. Si ces fichiers de configuration ne sont pas sécurisés, toute personne avec un accès aux systèmes ou aux dépôts peut accéder à ces informations d’identification et risquer une exposition.

Azure AD résout ce problème au moyen de deux méthodes : les principaux de service et les identités managées pour les services Azure.

Image représentant différents rôles

Principaux de service

Pour comprendre les principaux de service, vous devez d’abord comprendre les mots identité et principal, car ceux-ci sont largement utilisés dans la gestion des identités.

Une identité constitue simplement un élément pouvant être authentifié. Il s’agit évidemment des utilisateurs avec un nom d’utilisateur et un mot de passe, mais aussi des applications ou d’autres serveurs qui peuvent s’authentifier avec des clés secrètes ou des certificats.

Un principal est une identité agissant avec certains rôles ou certaines revendications. Souvent, le principal et l’identité n’ont pas besoin d’être différenciés, mais imaginez que vous utilisez « sudo » sur une invite Bash dans Linux ou « exécuter en tant qu’administrateur » sur Windows. Dans les deux cas vous êtes connecté avec la même identité, mais vous avez changé le rôle sous lequel vous exécutez la session. Les groupes sont également souvent considérés comme des principaux dans la mesure où l’on peut leur attribuer des droits.

Un principal de service est une identité utilisée par un service ou une application. Comme les autres identités, des rôles peuvent lui être attribués.

Image représentant des identités managées

Identités managées pour les services Azure

La création des principaux de service peut être fastidieuse et les nombreux points de contact peuvent rendre leur maintenance difficile. Les identités managées pour les services Azure sont beaucoup plus simples et effectuent la plus grande partie du travail pour vous.

Une identité managée peut être créée instantanément pour tous les services Azure qui la prennent en charge (la liste s’allonge constamment). Lorsque vous créez une identité managée pour un service, vous créez un compte sur l’instance Active Directory de votre organisation (une instance Active Directory d’une organisation spécifique est appelée « locataire Active Directory »). L’infrastructure Azure se charge automatiquement de l’authentification du service et de la gestion du compte. Vous pouvez ensuite utiliser ce compte comme n’importe quel autre compte Azure AD, et notamment autoriser le service authentifié à accéder de manière sécurisée aux autres ressources Azure.

Contrôle d’accès en fonction du rôle
Les rôles sont des ensembles d’autorisations, comme « Lecture seule » ou « Contributeur », que les utilisateurs peuvent obtenir pour accéder à une instance de service Azure.

Les identités sont mappées aux rôles directement ou à travers l’appartenance à un groupe. La séparation des principaux de sécurité, des autorisations d’accès et des ressources permet un contrôle précis et une gestion simple des accès. Les administrateurs peuvent s’assurer que le nombre minimal d’autorisations nécessaires soit accordé.

Les rôles peuvent être accordés au niveau d’une instance de service, mais ils suivent également la hiérarchie d’Azure Resource Manager.

Voici un diagramme qui montre cette relation. Les rôles attribués à une étendue supérieure, par exemple tout un abonnement, sont hérités par les étendues enfants, par exemple des instances de service.

Illustration montrant la représentation hiérarchique de l’accès en fonction du rôle dans un groupe d’administration.

Privileged Identity Management
Outre la gestion des accès aux ressources Azure avec le contrôle d’accès en fonction du rôle (RBAC), une approche complète de la protection de l’infrastructure doit prendre en compte l’intégration de l’audit continu des membres de rôle suivant l’évolution et les changements de l’organisation. Azure AD Privileged Identity Management (PIM) est une offre payante complémentaire permettant de superviser les attributions de rôles, le libre-service et l’activation de rôle juste-à-temps. Il permet également de procéder à des examens des accès pour les ressources Azure AD et Azure.

Capture d’écran du tableau de bord Privileged Identity Management

Résumé
L’identité nous permet de maintenir un périmètre de sécurité, même en dehors de notre contrôle physique. Avec l’authentification unique et la configuration d’accès en fonction du rôle appropriée, nous pouvons toujours vérifier qui a la possibilité de consulter et de manipuler notre infrastructure et nos données.







Chiffrement
8 minutes
Pour la plupart des organisations, les données constituent des ressources irremplaçables et les plus précieuses. Le chiffrement constitue la dernière et la plus forte ligne de défense dans une stratégie de sécurité par couche.

Contoso Shipping sait que le chiffrement est la seule protection de ses données une fois que celles-ci quittent le centre de données et sont stockées sur des appareils mobiles susceptibles d’être piratés ou volés.

Qu’est-ce que le chiffrement ?
Le chiffrement est le processus qui rend les données illisibles et inutilisables pour les utilisateurs non autorisés. Pour que les données chiffrées puissent être utilisées ou lues, elles doivent être déchiffrées, ce qui nécessite l’utilisation d’une clé secrète. Il existe deux types principaux de chiffrement : symétrique et asymétrique.

Le chiffrement symétrique utilise la même clé pour chiffrer et pour déchiffrer les données. Imaginez que vous utilisez une application gestionnaire de mots de passe de bureau. Vous entrez vos mots de passe et ils sont chiffrés avec votre propre clé personnelle (votre clé est souvent dérivée de votre mot de passe principal). Pour récupérer les données, vous utilisez la même clé pour les déchiffrer.

Le chiffrement asymétrique utilise une clé publique et une paire de clés privées. Chaque clé peut chiffrer des données, mais une même clé ne peut pas déchiffrer ses propres données chiffrées. Pour déchiffrer les données, vous avez besoin de la clé associée. Le chiffrement asymétrique est utilisé par exemple pour le protocole TLS (utilisé dans HTTPS) et la signature des données.

Les chiffrements symétrique et asymétrique contribuent à sécuriser vos données de manière appropriée. Le chiffrement est généralement implémenté de deux façons :

Chiffrement au repos
Chiffrement en transit
Chiffrement au repos
Les données au repos sont les données qui ont été stockées sur un support physique. Elles peuvent être stockées sur le disque d’un serveur, dans une base de données ou dans un compte de stockage. Quel que soit le mécanisme de stockage, le chiffrement de données au repos garantit que les données stockées sont illisibles sans les clés et les secrets nécessaires pour les déchiffrer. Si un attaquant obtient un disque dur avec des données chiffrées et qu’il n’a pas accès aux clés de chiffrement, il lui sera très difficile de compromettre les données.

Les données réelles chiffrées peuvent varier dans leur contenu, leur utilisation et leur importance pour l’organisation. Il peut s’agir d’informations financières critiques pour l’entreprise, d’éléments soumis à la propriété intellectuelle qui ont été développés par l’entreprise, de données personnelles que l’entreprise stocke concernant les clients ou les employés, et même des clés et des secrets utilisés pour le chiffrement des données.

Voici un diagramme qui montre à quoi devraient ressembler les données chiffrées du client quand elles sont dans une base de données.

Illustration montrant un exemple de chiffrement au repos. Les données sont enregistrées dans le stockage sous une forme chiffrée accessible uniquement par le biais d’une clé.

Chiffrement en transit
Les données en transit sont les données activement déplacées d’un endroit à un autre, comme sur Internet ou via un réseau privé. Un transfert sécurisé peut être géré par plusieurs couches différentes. Il peut être effectué en chiffrant les données au niveau de la couche application avant de les envoyer sur un réseau. HTTPS est un exemple de chiffrement de couche application en transit.

Vous pouvez également configurer un canal sécurisé, comme un VPN, au niveau d’une couche réseau pour transmettre des données entre deux systèmes.

Le chiffrement des données en transit protège les données des observateurs externes, et fournit un mécanisme de transmission des données tout en limitant le risque d’exposition.

Ce diagramme présente ce processus. Ici, les données du client sont chiffrées quand elles sont envoyées sur le réseau. Seul le destinataire a la clé secrète qui peut déchiffrer les données dans un format utilisable.

Illustration montrant un exemple de chiffrement en transit. Les données sont chiffrées avant d’être transférées. Une fois arrivées à destination, les données sont déchiffrées.

Chiffrement dans Azure
Voyons quelques moyens par lesquels Azure vous permet de chiffrer les données dans les services.

Image représentant le stockage chiffré

Chiffrer le stockage brut

Azure Storage Service Encryption pour les données au repos vous permet de protéger vos données conformément aux engagements de votre organisation en matière de sécurité et de conformité. Avec cette fonctionnalité, la plateforme de stockage Azure chiffre automatiquement vos données avant de les stocker de manière persistante dans Disques managés Azure, Stockage Blob Azure, Azure Files ou Stockage File d’attente Azure, et elle déchiffre ces données avant leur récupération. La gestion du chiffrement, du chiffrement au repos, du déchiffrement et des clés dans Storage Service Encryption est transparente pour les applications qui utilisent les services.

Image représentant une machine virtuelle chiffrée

Chiffrer les disques de machine virtuelle

Storage Service Encryption offre une protection par chiffrement de bas niveau pour les données écrites sur un disque physique, mais comment protéger les disques durs virtuels des machines virtuelles ? Si des attaquants malveillants parviennent à accéder à votre abonnement Azure et obtenir les disques durs virtuels de vos machines virtuelles, comment être sûr qu’ils ne pourront pas accéder aux données qui y sont stockées ?

Azure Disk Encryption est une fonctionnalité qui vous permet de chiffrer vos disques de machine virtuelle IaaS Windows et Linux. Azure Disk Encryption s’appuie sur la fonctionnalité standard BitLocker de Windows et sur la fonctionnalité dm-crypt de Linux pour assurer le chiffrement des volumes des disques de système d’exploitation et des disques de données. La solution est intégrée à Azure Key Vault, ce qui vous permet de contrôler et de gérer les clés et les secrets de chiffrement de disque (et vous pouvez utiliser Managed Service Identity pour accéder au coffre de clés).

Pour Contoso Shipping, l’utilisation de machines virtuelles était l’une de leurs premières étapes vers l’utilisation du cloud. Le chiffrement de tous les disques durs virtuels est un moyen simple et à faible impact garantissant que vous faites votre possible pour sécuriser les données de votre entreprise.

Image représentant une base de données chiffrée

Chiffrer les bases de données

TDE (Transparent Data Encryption) aide à protéger Azure SQL Database et Azure Data Warehouse contre les menaces d’activité malveillante. TDE chiffre et déchiffre en temps réel la base de données, les sauvegardes associées et les fichiers journaux de transactions au repos, sans changer l’application. Par défaut, TDE est activé pour toutes les bases de données SQL Azure nouvellement déployées.

TDE chiffre le stockage de l’ensemble de la base de données avec une clé symétrique, appelée « clé de chiffrement de base de données ». Par défaut, Azure fournit une clé de chiffrement unique par instance logique de SQL Server et gère tous les détails. BYOK (Bring Your Own Key) est également pris en charge avec des clés stockées dans Azure Key Vault (voir plus loin).

Comme TDE est activé par défaut, Contoso Shipping est assuré de disposer des protections appropriées pour les données stockées dans les bases de données de l’entreprise.

Image représentant un secret chiffré

Chiffrer des secrets

Nous avons vu que les services de chiffrement utilisent tous des clés pour chiffrer et déchiffrer les données ; aussi, comment être sûr que les clés elles-mêmes sont sécurisées ? Les sociétés peuvent également avoir des mots de passe, des chaînes de connexion ou d’autres informations sensibles à stocker de manière sécurisée. Dans Azure, vous pouvez protéger vos secrets à l’aide du service Azure Key Vault.

Azure Key Vault est un service cloud centralisé conçu pour le stockage des secrets d’application. Key Vault vous aide à gérer les secrets de vos applications en les conservant dans un emplacement central unique et en fournissant des fonctionnalités d’accès sécurisé, de contrôle des autorisations et de journalisation des accès. Ce service est utile dans divers scénarios :

Gestion des secrets. Vous pouvez utiliser Key Vault pour stocker en toute sécurité les jetons, mots de passe, certificats, clés API (interface de programmation d’applications) et autres secrets, et pour contrôler étroitement l’accès à tous ces secrets.
Gestion des clés. Vous pouvez également utiliser Key Vault comme solution de gestion des clés. Key Vault simplifie la création et le contrôle des clés de chiffrement utilisées pour chiffrer vos données.
Gestion des certificats. Key Vault vous aide à provisionner, gérer et déployer vos certificats SSL/TLS (Secure Sockets Layer/Transport Layer Security) publics et privés pour vos ressources Azure et vos ressources connectées internes.
Stockage de secrets secondé par des modules de sécurité matériels (HSM). Les secrets et les clés peuvent être protégés par logiciel ou par des modules de sécurité matériels approuvés FIPS 140-2 de niveau 2.
Les avantages de l’utilisation de Key Vault sont les suivants :

Centralisation des secrets d’application. La centralisation du stockage des secrets d’application vous permet de contrôler la distribution des secrets et réduit les risques de fuite accidentelle des secrets.
Stockage sécurisé des secrets et des clés. Azure utilise des algorithmes, des longueurs de clé et des modules HSM standard, et l’accès nécessite une autorisation et une authentification appropriées.
Supervision des accès et de l’utilisation. Key Vault vous permet de superviser et contrôler l’accès aux secrets de l’entreprise.
Administration simplifiée des secrets d’application. Key Vault facilite l’inscription et le renouvellement des certificats auprès des autorités de certification publiques. Vous pouvez aussi effectuer un scale-up et répliquer du contenu dans plusieurs régions, et utiliser des outils de gestion de certificats standard.
Intégration dans d’autres services Azure. Vous pouvez intégrer Key Vault dans des comptes de stockage, des registres de conteneurs, des hubs d’événements et de nombreux autres services Azure.
Comme les identités Azure AD peuvent être autorisées à utiliser des secrets Azure Key Vault, les applications pour lesquelles Managed Service Identity est activé peuvent obtenir de manière automatique et fluide les secrets dont elles ont besoin.

Résumé
Comme vous le savez peut-être, le chiffrement est souvent la dernière couche de défense contre les attaquants et il joue un rôle important dans l’approche en couche de la sécurisation de vos systèmes. Azure fournit des fonctionnalités et des services intégrés pour chiffrer et protéger les données contre les expositions involontaires. La protection des données des clients stockées au sein des services Azure est d’une importance capitale pour Microsoft et elle doit être incluse dans toutes les conceptions. Des services fondamentaux comme le Stockage Azure, les Machines virtuelles Azure, Azure SQL Database et Azure Key Vault peuvent aider à sécuriser votre environnement à travers le chiffrement.

Unité suivante: Vue d’ensemble des certificats Azure





Protéger votre réseau
8 minutes
Dans n’importe quelle architecture, la sécurisation de votre réseau contre les attaques et les accès non autorisés occupe une place importante. Nous verrons ici à quoi ressemble la sécurité réseau, comment intégrer une approche en couche à votre architecture et comment Azure peut vous aider à assurer la sécurité réseau de votre environnement.

Approche en couche de la sécurité réseau
Vous avez probablement noté qu’un thème commun développé tout au long de ce module est une approche en couche de la sécurité. Cette approche est également recommandée au niveau de la couche réseau. La sécurisation du périmètre de réseau en elle-même ne suffit pas, ni même la sécurité réseau entre les services à l’intérieur d’un réseau. Une approche en couche offre plusieurs niveaux de protection. De cette façon, si un attaquant passe à travers une couche, les autres protections en place limitent encore l’attaque.

Voyons comment Azure peut fournir des outils pour une approche en couches de la sécurisation de l’empreinte de votre réseau.

Image représentant une connexion Internet sécurisée

Protection d’Internet

Si nous commençons par le périmètre du réseau, nous devons limiter et éliminer les attaques en provenance d’Internet. Nous suggérons de d’abord évaluer les ressources accessibles sur Internet, et d’autoriser uniquement les communications entrantes et sortantes en fonction des besoins. Assurez-vous d’identifier toutes les ressources qui autorisent le trafic réseau entrant, quel que soit son type, et vérifiez qu’elles sont restreintes aux seuls ports et protocoles nécessaires. Azure Security Center est l’endroit idéal pour rechercher ces informations, car il identifie les ressources accessibles sur Internet qui ne sont pas associées à un groupe de sécurité réseau, ainsi que celles qui ne sont pas sécurisées derrière un pare-feu.

Qu’est-ce qu’un pare-feu ?
Un pare-feu est un service qui accorde l’accès au serveur en fonction de l’adresse IP d’origine de chaque requête. Vous pouvez créer des règles de pare-feu qui spécifient des plages d’adresses IP. Seuls les clients ayant accès à ces adresses IP sont autorisés à accéder au serveur. En règle générale, les règles de pare-feu comprennent également des informations de port et de protocole réseau spécifiques.

Pour assurer une protection du trafic entrant au niveau du périmètre, vous avez plusieurs solutions possibles.

Le Pare-feu Azure est un service de sécurité réseau managé dans le cloud qui protège vos ressources Réseau virtuel Azure. Il s’agit d’un service de pare-feu avec état intégral, doté d’une haute disponibilité intégrée et d’une scalabilité illimitée dans le cloud. Le Pare-feu Azure offre une protection du trafic entrant pour les protocoles autres que HTTP/S. Voici des exemples de ces protocoles : Protocole RDP (Remote Desktop Protocol), Secure Shell (SSH) et FTP (File Transfer Protocol). Le service assure également une protection en sortie au niveau du réseau pour tous les ports et protocoles, ainsi qu’une protection au niveau de l’application pour le trafic HTTP/S sortant.

Azure Application Gateway est un équilibreur de charge qui inclut un pare-feu d’applications web (WAF) fournissant une protection contre les vulnérabilités connues et courantes sur les sites web. Il est conçu pour protéger le trafic HTTP.

Les appliances réseau virtuelles sont des options idéales pour les services ou configurations avancées non-HTTP. Elles sont similaires aux appliances de pare-feu matérielles.

Arrêt des attaques par déni de service distribué (DDoS)
Toute ressource accessible sur Internet est susceptible de subir une attaque par déni de service. Ce type d’attaque tente de surcharger une ressource réseau en envoyant un nombre de requêtes si grand que la ressource ralentit ou ne répond plus.

En combinant le service Azure DDoS Protection avec de bonnes pratiques de conception d’application, vous renforcez votre défense contre les attaques par déni de service distribué. DDoS Protection se sert des capacités d’échelle et d’élasticité du réseau mondial de Microsoft pour implémenter l’atténuation DDoS dans chaque région Azure. Le service Azure DDoS Protection protège vos applications Azure en supervisant le trafic en périphérie du réseau Azure avant même que le trafic impacte la disponibilité de votre service. Quelques minutes après la détection de l’attaque, vous êtes informé avec les métriques Azure Monitor.

Ce diagramme illustre le trafic réseau qui part à la fois de clients et d’un attaquant vers Azure. La protection Azure DDoS identifie la tentative de l’attaquant de submerger le réseau et empêche le trafic d’atteindre les services Azure. Le trafic légitime des clients continue d’être acheminé dans Azure sans interruption de service.

Illustration montrant la protection Azure DDoS installée entre le réseau virtuel et les demandes des utilisateurs externes. La protection Azure DDoS bloque le trafic malveillant, mais transfère le trafic légitime vers la destination prévue.

Azure DDoS Protection offre les niveaux de service suivants :

De base : Le niveau de service De base est automatiquement activé sur la plateforme Azure. La supervision permanente du trafic et l’atténuation en temps réel des attaques courantes au niveau du réseau fournissent les mêmes défenses que celles utilisées par les services en ligne de Microsoft. Le réseau mondial d’Azure est utilisé pour distribuer et atténuer le trafic d’attaque dans les régions.
Standard : Le niveau de service Standard fournit des fonctionnalités d’atténuation supplémentaires conçues spécifiquement pour les ressources de réseau virtuel Azure. DDoS Protection Standard est facile à activer et ne nécessite aucun changement dans l’application. Les stratégies de protection sont paramétrées à l’aide d’algorithmes de supervision du trafic et de machine learning dédiés. Elles sont appliquées aux adresses IP publiques associées aux ressources déployées sur des réseaux virtuels, comme Azure Load Balancer et Application Gateway. La protection DDoS Standard peut atténuer les types d’attaques suivants :
Attaques volumétriques. L’objectif de ces attaques est de submerger la couche réseau d’une grande quantité de trafic apparemment légitime.
Attaques de protocole. Ces attaques rendent une cible inaccessible, en exploitant une faille dans la pile de protocole des couches 3 et 4.
Attaques de la couche Ressource (application). Ces attaques ciblent les paquets d’application web pour interrompre la transmission des données entre des hôtes.
Contrôle du trafic au sein de votre réseau virtuel
Image représentant un réseau virtuel sécurisé

Sécurité des réseaux virtuels

Dans un réseau virtuel, il est crucial de limiter au strict nécessaire la communication entre les ressources.

Les groupes de sécurité réseau (NSG) jouent un rôle essentiel pour limiter les communications inutiles entre les machines virtuelles.

Ils vous permettent de filtrer le trafic réseau à destination et en provenance des ressources Azure dans un réseau virtuel Azure. Un groupe de sécurité réseau peut contenir plusieurs règles de sécurité entrantes et sortantes avec lesquelles vous filtrez le trafic échangé avec les ressources par adresse IP source et de destination, port et protocole. Les groupes de sécurité réseau fournissent une liste des communications autorisées et refusées vers/à partir des interfaces réseau et des sous-réseaux, et sont entièrement personnalisables.

Vous pouvez supprimer complètement l’accès Internet public à vos services en limitant l’accès aux points de terminaison des services. Avec les points de terminaison de service, les accès au service Azure peuvent être limités à votre réseau virtuel.

Image représentant un réseau sécurisé

Intégration réseau

Il est courant d’avoir une infrastructure réseau qui doit être intégrée pour autoriser les communications à partir de réseaux locaux, ou pour améliorer la communication entre services dans Azure. Il existe plusieurs façons de gérer cette intégration et d’améliorer la sécurité de votre réseau.

Les connexions de réseau privé virtuel (VPN) sont une méthode courante pour établir des canaux de communication sécurisés entre réseaux. Les connexions entre Réseau virtuel Azure et un appareil VPN local sont un excellent moyen d’établir une communication sécurisée entre votre réseau et votre réseau virtuel sur Azure.

Pour établir une connexion privée dédiée entre votre réseau et Azure, vous pouvez utiliser Azure ExpressRoute. ExpressRoute vous permet d’étendre vos réseaux locaux au cloud Microsoft via une connexion privée facilitée par un fournisseur de connectivité. Avec ExpressRoute, vous pouvez établir des connexions aux services cloud de Microsoft, comme Microsoft Azure, Office 365 et Dynamics 365. Les connexions ExpressRoute renforcent la sécurité de vos communications locales en envoyant ce trafic sur le circuit privé au lieu de l’Internet public. Vous n’avez pas besoin d’accorder à vos utilisateurs finaux l’accès à ces services sur l’Internet public et vous pouvez envoyer ce trafic via des appliances pour pouvoir l’inspecter davantage.

Résumé
Une approche en couche de la sécurité du réseau permet de réduire les risques d’exposition liés aux attaques basées sur le réseau. Azure fournit plusieurs services et fonctionnalités pour sécuriser vos ressources accessibles sur Internet, vos ressources internes et la communication entre des réseaux locaux. Avec ces fonctionnalités, vous avez les moyens de concevoir des solutions sécurisées sur Azure.

Vous pouvez aussi combiner plusieurs services de sécurité et réseau Azure pour mieux contrôler la sécurité de votre réseau et renforcer la protection multicouche. Par exemple, utilisez le Pare-feu Azure pour protéger le trafic Internet entrant et sortant, et utilisez les groupes de sécurité réseau pour restreindre le trafic vers les ressources au sein de vos réseaux virtuels.






Comprendre les considérations relatives à la sécurité pour les solutions de gestion du cycle de vie des applications
8 minutes
Microsoft Security Development Lifecycle (SDL) présente des considérations relatives à la sécurité et à la confidentialité tout au long des phases du processus de développement. Il permet aux développeurs de créer des logiciels hautement sécurisés, de répondre aux exigences de conformité de sécurité et de réduire les coûts de développement. Les conseils, bonnes pratiques, outils et processus de SDL sont des pratiques utilisées en interne chez Microsoft pour créer des produits et services plus sécurisés.

Depuis la première fois que nous avons partagé SDL en 2008, les pratiques ont été continuellement mises à jour pour couvrir de nouveaux scénarios comme les services cloud, IoT et IA.

Fournir des formations
La sécurité est le travail de tout le monde. Les développeurs, les ingénieurs du service ainsi que les chefs de projet et de programme doivent comprendre les principes fondamentaux de la sécurité. Ils doivent tous savoir comment intégrer la sécurité aux logiciels et services afin de rendre les produits plus sûrs, tout en continuant de répondre aux besoins métier et de fournir une valeur utilisateur. Une formation efficace vient compléter et renforcer les stratégies de sécurité, les pratiques SDL, les standards et les exigences de la sécurité des logiciels, en étant guidée par des insights dérivés de données ou de nouvelles fonctionnalités techniques.

Bien que la sécurité soit le travail de tous, il est important de rappeler que tout le monde n’a pas besoin d’être un expert en sécurité, ni de devenir un testeur compétent en matière d’intrusion. Toutefois, l’assurance que tout le monde comprend le point de vue de l’attaquant, ses objectifs et l’art du possible permet de capter l’attention de chacun et d’élever le niveau de connaissances collectif.

Définir les exigences de sécurité
La sécurité et la confidentialité sont un aspect fondamental du développement d’applications et de systèmes hautement sécurisés. Quelle que soit la méthodologie de développement utilisée, les exigences de sécurité doivent être continuellement mises à jour pour faire face aux modifications apportées aux fonctionnalités nécessaires et au paysage des menaces. Le meilleur moment pour définir les exigences de sécurité a lieu au cours des phases de conception et de planification initiales. La planification précoce permet aux équipes de développement d’intégrer la sécurité de manière à minimiser les perturbations.

Les facteurs qui influencent les exigences de sécurité incluent (sans s’y limiter) :

les exigences légales et industrielles ;
les standards internes et les pratiques de programmation ;
l’examen des incidents précédents ;
les menaces connues.
Ces exigences doivent être suivies à l’aide d’un système de suivi de travail ou par télémétrie dérivée du pipeline d’ingénierie.

Définir les métriques et les rapports de conformité
Il est essentiel pour une organisation de définir les niveaux minimum de qualité de sécurité acceptables et de responsabiliser les équipes d’ingénieurs pour qu’elles répondent à ces critères. La définition de ces attentes au plus tôt aide une équipe à comprendre les risques associés aux problèmes de sécurité, à identifier et à corriger les défauts de sécurité au cours du développement et à appliquer les normes pendant tout le projet. La définition d’une barre de sécurité significative implique de définir clairement les seuils de gravité des vulnérabilités de sécurité et aide à établir un plan d’action quand des vulnérabilités sont rencontrées. Par exemple, toutes les vulnérabilités connues découvertes avec un niveau de gravité « critique » ou « important » doivent être corrigées dans un laps de temps spécifié.

Pour effectuer le suivi des indicateurs de performance clés (KPI) et vérifier que les tâches de sécurité sont terminées, les mécanismes de suivi des bogues et/ou suivi du travail utilisés par une organisation (comme Azure DevOps) doivent autoriser les défauts de sécurité et les éléments de travail de sécurité à être clairement étiquetés comme relevant de la sécurité et marqués avec le niveau de gravité approprié. Cela permet un suivi et des rapports précis relatifs au travail de sécurité.

Pour en savoir plus sur la définition des métriques et des rapports de conformité, consultez :

Exemple de barre de bogues de confidentialité SDL
Ajouter ou modifier un champ Azure DevOps pour suivre le travail
Exemple de barre de bogues de sécurité SDL
Effectuer la modélisation des menaces
La modélisation des menaces doit être utilisée dans les environnements où il existe un risque de sécurité significatif. En pratique, elle permet aux équipes de développement de prendre en compte, documenter et discuter des implications de la sécurité des conceptions dans le contexte de leur environnement d’exploitation prévu et de manière structurée. L’application d’une approche structurée aux scénarios de menaces aide une équipe à identifier les vulnérabilités de sécurité de manière plus efficace et moins coûteuse, à déterminer les risques liés à ces menaces, à effectuer des sélections de fonctionnalités de sécurité et à établir les mesures d’atténuation appropriées. Vous pouvez appliquer la modélisation des menaces au niveau du composant, de l’application ou du système.

Pour plus d’informations, consultez Modélisation des menaces.

Établir des exigences de conception
Security Development Lifecycle implique généralement des activités d’assurance qui aident les ingénieurs à implémenter des fonctionnalités plus sécurisées, ce qui signifie que les fonctionnalités sont bien conçues pour la sécurité. Pour y parvenir, les ingénieurs s’appuient généralement sur des fonctionnalités de sécurité telles que le chiffrement, l’authentification et la journalisation. Dans de nombreux cas, la sélection ou l’implémentation de fonctionnalités de sécurité s’avère tellement compliquée que les choix de conception ou d’implémentation sont susceptibles d’entraîner des vulnérabilités. Il est donc essentiel qu’elles soient appliquées de manière cohérente avec une parfaite compréhension de la protection qu’elles fournissent.

Définir et utiliser les normes de chiffrement
Avec la hausse des appareils mobiles et du cloud computing, il est important de vérifier que toutes les données, notamment les informations sensibles sur la sécurité ainsi que les données de gestion et de contrôle, sont protégées contre toute divulgation ou modification involontaire lorsqu’elles sont transmises ou stockées. Le chiffrement est généralement utilisé dans ce but. Toutefois, un mauvais choix lors de l’utilisation de n’importe quel aspect du chiffrement peut être catastrophique. Il est donc préférable de développer des standards de chiffrement claires qui fournissent des détails sur chaque élément de l’implémentation de chiffrement.

Le chiffrement doit être laissé aux experts. Il est généralement judicieux d’utiliser uniquement des bibliothèques de chiffrement approuvées par le secteur et de s’assurer qu’elles sont implémentées de manière à être facilement remplacées si nécessaire.

Pour plus d’informations sur le chiffrement, consultez le livre blanc Microsoft SDL Cryptographic Recommendations.

Gérer les risques de sécurité liés à l’utilisation de composants tiers
La grande majorité des projets logiciels sont créés à l’aide de composants tiers (à la fois commerciaux et open source). Quand vous sélectionnez les composants tiers à utiliser, il est important de comprendre l’impact qu’une faille de sécurité qu’ils peuvent contenir peut avoir sur la sécurité du système plus large auquel ils sont intégrés. Le fait de disposer d’un inventaire précis de ces composants et d’un plan de réponse lors de la détection de nouvelles vulnérabilités contribue dans une large mesure à atténuer ces risques. Toutefois, vous devez également envisager une validation supplémentaire, en fonction de la tolérance au risque de votre organisation, du type de composant utilisé et de l’impact potentiel d’une faille de sécurité.

Découvrez plus d’informations sur la gestion des risques de sécurité liés à l’utilisation de composants tiers sur :

Open source
Gestion des risques de sécurité inhérents à l’utilisation de composants tiers
Gestion des risques de sécurité inhérents à l’utilisation de logiciels open source
Utiliser des outils approuvés
Définissez et publiez une liste d’outils approuvés et des contrôles de sécurité qui leur sont associés, tels que les avertissements et les options du compilateur et de l’éditeur de liens. Les ingénieurs doivent s’efforcer d’utiliser la dernière version des outils approuvés (comme les versions du compilateur) ainsi que les nouvelles protections et fonctionnalités d’analyse de sécurité.

Pour plus d’informations, consultez :

Outils, compilateurs et options recommandés pour les processeurs x86, x64 et ARM (livre blanc)
Ressources SDL
Effectuer des tests de sécurité des applications statiques
L’analyse du code source avant la compilation offre une méthode hautement scalable de révision du code de sécurité et permet de garantir que les stratégies de programmation sécurisées sont respectées. Les tests de sécurité des applications statiques sont généralement intégrés au pipeline de validation pour identifier les vulnérabilités chaque fois que le logiciel est généré ou empaqueté. Toutefois, quelques offres s’intègrent à l’environnement de développement afin de repérer certains défauts tels que l’existence de fonctions non fiables ou interdites, puis de les remplacer par des alternatives plus sûres pendant que le développeur programme activement. Il n’existe pas de solution universelle. Les équipes de développement doivent décider de la fréquence optimale pour l’exécution des tests de sécurité des applications statiques et envisager de déployer plusieurs tactiques pour équilibrer la productivité avec une couverture de sécurité adéquate.

Pour plus d’informations, consultez :

Microsoft DevSkim sur GitHub
Règles Roslyn Security Guard
Visual Studio Marketplace
Analyse de la qualité du code C/C++ à l’aide de l’analyse du code
Microsoft BinSkim sur GitHub
Effectuer des tests de sécurité des analyses dynamiques
La réalisation de la vérification au moment de l’exécution de votre logiciel entièrement compilé ou empaqueté vérifie les fonctionnalités qui ne sont visibles que lorsque tous les composants sont intégrés et en cours d’exécution. Cette vérification s’effectue généralement à l’aide d’un outil, d’une suite d’attaques prédéfinies ou d’outils qui supervisent spécifiquement le comportement de l’application en cas d’altération de la mémoire, de problèmes de privilèges utilisateur et d’autres problèmes de sécurité critiques. Comme pour les tests de sécurité des applications statiques, il n’existe pas de solution universelle et, bien que certains outils (tels que les outils d’analyse d’applications web) peuvent être plus facilement intégrés au pipeline CI/CD, d’autres tests de sécurité des applications dynamiques, tels que le test à données aléatoires (fuzzing), nécessitent une approche différente.

Pour plus d’informations, consultez :

Visual Studio Marketplace
Tests d’intrusion automatisés avec test à données aléatoires (fuzzing) de boîte blanche
Effectuer des tests d’intrusion
Les tests d’intrusion correspondent à une analyse de la sécurité d’un système logiciel effectuée par des professionnels de la sécurité compétents qui simulent les actions d’un hacker. L’objectif d’un test d’intrusion est de dévoiler les vulnérabilités potentielles résultant d’erreurs de programmation, de défaillances de configuration du système ou d’autres faiblesses de déploiement d’exploitation. Les tests d’intrusion recherchent généralement le plus grand nombre de vulnérabilités et sont souvent associés à des révisions de code automatisées et manuelles pour fournir un niveau d’analyse plus approfondi qu’il n’est généralement possible.

Pour plus d’informations, consultez :

Analyseur de surface d’attaque
Exemple de barre de bogues de sécurité SDL
Établir un processus de réponse aux incidents standard
La préparation d’un plan de réponse aux incidents est cruciale pour vous aider à déjouer les nouvelles menaces susceptibles d’émerger au fil du temps. Il doit être créé en collaboration avec l’équipe de réponse aux incidents de sécurité des produits (PSIRT) dédiée de votre organisation. Votre plan de réponse aux incidents doit :

Inclure les personnes à contacter en cas d’urgence de sécurité
Établir le protocole pour la maintenance de sécurité, dont les plans pour le code hérité d’autres groupes au sein de l’organisation et pour le code tiers
être testé avant qu’il ne soit nécessaire.
Pour plus d’informations sur les réponses aux incidents, consultez :

Utilisation d’Azure Security Center pour la réponse aux incidents
Réponse aux incidents Microsoft et responsabilité partagée pour cloud computing
Centre de réponse aux problèmes de sécurité Microsoft
En introduisant des considérations de sécurité et de conformité standardisées dans toutes les phases du processus de développement, les développeurs peuvent réduire la probabilité de vulnérabilités dans les produits et les services, et éviter de répéter les mêmes erreurs de sécurité. De même, l’intégration de la sécurité tout au long du cycle de vie des opérations contribuera à préserver l’intégrité de ces produits et services. Ces pratiques OSA (Operational Security Assurance) doivent s’aligner sur les processus de développement. Ainsi, vous consacrez moins de temps, et donc moins d’argent, à trier et à répondre après les faits, tout en donnant à vos clients la garantie que vos produits sont hautement sécurisés.

